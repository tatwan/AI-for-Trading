{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Breakout Strategy\n",
    "## Instructions\n",
    "Each problem consists of a function to implement and instructions on how to implement the function.  The parts of the function that need to be implemented are marked with a `# TODO` comment. After implementing the function, run the cell to test it against the unit tests we've provided. For each problem, we provide one or more unit tests from our `project_tests` package. These unit tests won't tell you if your answer is correct, but will warn you of any major errors. Your code will be checked for the correct solution when you submit it to Udacity.\n",
    "\n",
    "## Packages\n",
    "When you implement the functions, you'll only need to use the [Pandas](https://pandas.pydata.org/) and [Numpy](http://www.numpy.org/) packages. Don't import any other packages, otherwise the grader will not be able to run your code.\n",
    "\n",
    "The other packages that we're importing is `helper`, `project_helper`, and `project_tests`. These are custom packages built to help you solve the problems.  The `helper` and `project_helper` module contains utility functions and graph functions. The `project_tests` contains the unit tests for all the problems.\n",
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helper\n",
    "import project_helper\n",
    "import project_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Data\n",
    "The data source we'll be using is the [Wiki End of Day data](https://www.quandl.com/databases/WIKIP) hosted at [Quandl](https://www.quandl.com). This contains data for many stocks, but we'll just be looking at the S&P 500 stocks. We'll also make things a little easier to solve by narrowing our range of time from 2007-06-30 to 2017-09-30.\n",
    "### Set API Key\n",
    "Set the `quandl_api_key` variable to your Quandl api key. You can find your Quandl api key [here](https://www.quandl.com/account/api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add your Quandl API Key\n",
    "quandl_api_key  = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "snp500_file_path = 'data/tickers_SnP500.txt'\n",
    "wiki_file_path = 'data/WIKI_PRICES.csv'\n",
    "start_date, end_date = '2013-07-01', '2017-06-30'\n",
    "use_columns = ['date', 'ticker', 'adj_open', 'adj_close', 'adj_high', 'adj_low']\n",
    "\n",
    "if not os.path.exists(wiki_file_path):\n",
    "    with open(snp500_file_path) as f:\n",
    "        tickers = f.read().split()\n",
    "    \n",
    "    helper.download_quandl_dataset(quandl_api_key, 'WIKI', 'PRICES', wiki_file_path, use_columns, tickers, start_date, end_date)\n",
    "else:\n",
    "    print('Data already downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "While using real data will give you hands on experience, it's doesn't cover all the topics we try to condense in one project. We'll solve this by creating new stocks. We've create a scenario where companies mining [Terbium](https://en.wikipedia.org/wiki/Terbium) are making huge profits. All the companies in this sector of the market are made up. They represent a sector with large growth that will be used for demonstration latter in this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_original = pd.read_csv(wiki_file_path, parse_dates=['date'], index_col=False)\n",
    "\n",
    "# Add TB sector to the market\n",
    "df = df_original\n",
    "df = pd.concat([df] + project_helper.generate_tb_sector(df[df['ticker'] == 'AAPL']['date']), ignore_index=True)\n",
    "\n",
    "print('Loaded Dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "In this project, you won't be building any charts.  We will provide all the code to plot or graph the data using our `project_helper` package. These charts will help you understand the data that you're working with.\n",
    "\n",
    "Let's see what a single stock looks like from the DataFrame we loaded, called `df`. For this example and future display examples, we'll use Apple's stock \"AAPL\". Run the code below to view a candlestick chart of Apple stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "apple_ticker = 'AAPL'\n",
    "project_helper.plot_stock(df[df['ticker'] == apple_ticker], '{} Stock'.format(apple_ticker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Alpha Research Process\n",
    "\n",
    "In this project you will code and evaluate a \"breakout\" signal. It is important to understand where these steps fit in the alpha research workflow. The signal-to-noise ratio in trading signals is very low and, as such, it is very easy to fall into the trap of _overfitting_ to noise. It is therefore inadvisable to jump right into signal coding. To help mitigate overfitting, it is best to start with a general observation and hypothesis; i.e., you should be able to answer the following question _before_ you touch any data:\n",
    "\n",
    "> What feature of markets or investor behaviour would lead to a persistent anomaly that my signal will try to exploit?\n",
    "\n",
    "Ideally the assumptions behind the hypothesis will be testable _before_ you actually code and evaluate the signal itself. The workflow therefore is as follows:\n",
    "\n",
    "![image](images/alpha_steps.png)\n",
    "\n",
    "In this project, we assume that the first three steps area done (\"observe & research\", \"form hypothesis\", \"validate hypothesis\"). The hypothesis you'll be using for this project is the following:\n",
    "- In the absence of news or significant investor trading interest, stocks oscillate in a range.\n",
    "- Traders seek to capitalize on this range-bound behaviour periodically by selling/shorting at the top of the range and buying/covering at the bottom of the range. This behaviour reinforces the existence of the range.\n",
    "- When stocks break out of the range, due to, e.g., a significant news release or from market pressure from a large investor:\n",
    "    - the liquidity traders who have been providing liquidity at the bounds of the range seek to cover their positions to mitigate losses, thus magnifying the move out of the range, _and_\n",
    "    - the move out of the range attracts other investor interest; these investors, due to the behavioural bias of _herding_ (e.g., [Herd Behavior](https://www.investopedia.com/university/behavioral_finance/behavioral8.asp)) build positions which favor continuation of the trend.\n",
    "\n",
    "\n",
    "Using this hypothesis, let start coding..\n",
    "## Compute the Highs and Lows in a Window\n",
    "You'll use highs and lows for an indicator to the breakout strategy. In this section, implement `get_high_lows_lookback` to get the maximum high price and minimum low price over a window of days. The variable `lookback_days` contains the number of days to look in the past. Make sure this doesn't include the current day. The implementation should return the maximum and minimum of the prices as a tuple of Pandas Series, where maximum high prices are a Series and minimum low prices are a Series.\n",
    "\n",
    "After implementing the function, run the cell to execute unit tests against your implementation.  If you pass the unit tests, it will display \"Tests Passed\". These tests are already added into the cells of each problem. In this problem, it's the line `project_tests.test_get_high_lows_lookback(get_high_lows_lookback)`.\n",
    "\n",
    "*Note: Any time we talk about closing prices, open prices, etc., you can assume we're talking about the adjusted prices.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_high_lows_lookback(df, lookback_days):\n",
    "    \"\"\"\n",
    "    Get the high and low in a lookback window.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Stock prices with dates and ticker symbols\n",
    "    lookback_days : int\n",
    "        The number of days to look back\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    high_lows_lookback : (Pandas Series, Pandas Series)\n",
    "        (High Lookbacks, Low Lookbacks)\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_get_high_lows_lookback(get_high_lows_lookback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's use your implementation of `get_high_lows_lookback` to get the high and lows for the past 50 days and compare it to it their respective stock.  Just like last time, we'll use Apple's stock as the example to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback_days = 50\n",
    "df['lookback_high'], df['lookback_low'] = get_high_lows_lookback(df, lookback_days)\n",
    "project_helper.plot_high_low(df[df['ticker'] == apple_ticker], 'High and Low of {} Stock'.format(apple_ticker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Long and Short Signals\n",
    "Using the generated indicator of highs and lows (columns \"lookback_low\" and \"lookback_high\" in `df`), create long and short signals using a breakout strategy. Implement `get_long_short` to generate the following signals:\n",
    "\n",
    "| Signal | Condition |\n",
    "|----|------|\n",
    "| -1 | Low > Close Price |\n",
    "| 1  | High < Close Price |\n",
    "| 0  | Otherwise |\n",
    "\n",
    "*Note: The **Close Price** is the adjusted close price. **Low** and **High** is the values from the columns \"lookback_low\" and \"lookback_high\" in df respectively.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_long_short(df):\n",
    "    \"\"\"\n",
    "    Generate the signals long, short, and do nothing.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Stock prices with dates and ticker symbols\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    long_short : Pandas Series\n",
    "        The long, short, and do nothing signals\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_get_long_short(get_long_short)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's compare the signals you generated against the Apple stock. This chart will show a lot of signals. Too many in fact. We'll talk about filtering the redundant signals in the next problem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['signal'] = get_long_short(df)\n",
    "project_helper.plot_signal(\n",
    "    df[df['ticker'] == apple_ticker],\n",
    "    'Long and Short of {} Stock'.format(apple_ticker),\n",
    "    'signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Signals\n",
    "That was a lot of repeated signals! If we're already shorting a stock, having an additional signal to short a stock isn't helpful for this strategy. This also applies to additional long signals when the last signal was long.\n",
    "\n",
    "Implement `filter_signals` to filter out repeated long or short signals within the `lookahead_days`. If the previous signal was the same, change the signal to `0` (do nothing signal). For example, say you have a single stock time series that is\n",
    "\n",
    "`[1,NAN,1,NAN,1,NAN,-1,-1]`\n",
    "\n",
    "Running `filter_signals` with a lookahead of 3 days should turn those signals into\n",
    "\n",
    "`[1, 0, 0, 0, 1, 0, -1, 0]`\n",
    "\n",
    "To help you implement the function, we have provided you with the `clear_signals` function. This will remove all signals within a window after the last signal. For example, say you're using a windows size of 3 with `clear_signals`. It would turn the Series of long signals\n",
    "\n",
    "`[0, 1, 0, 0, 1, 1, 0, 1, 0]`\n",
    "\n",
    "into\n",
    "\n",
    "`[0, 1, 0, 0, 0, 1, 0, 0, 0]`\n",
    "\n",
    "Note: it only takes a Series of the same type of signals, where `1` is the signal and `0` is no signal. It can't take a mix of long and short signals. Using this function, implement `filter_signals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_signals(signals, window_size):\n",
    "    \"\"\"\n",
    "    Clear out signals in a Series of just long or short signals.\n",
    "    \n",
    "    Remove the number of signals down to 1 within the window size time period.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signals : Pandas Series\n",
    "        The long, short, or do nothing signals\n",
    "    window_size : int\n",
    "        The number of days to have a single signal       \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    signals : Pandas Series\n",
    "        Signals with the signals removed from the window size\n",
    "    \"\"\"\n",
    "    # Start with buffer of window size\n",
    "    # This handles the edge case of calculating past_signal in the beginning\n",
    "    clean_signals = [0]*window_size\n",
    "    \n",
    "    for signal_i, current_signal in enumerate(signals):\n",
    "        # Check if there was a signal in the past window_size of days\n",
    "        has_past_signal = bool(sum(clean_signals[signal_i:signal_i+window_size]))\n",
    "        # Use the current signal if there's no past signal, else 0/False\n",
    "        clean_signals.append(not has_past_signal and current_signal)\n",
    "        \n",
    "    # Remove buffer\n",
    "    clean_signals = clean_signals[window_size:]\n",
    "\n",
    "    # Return the signals as a Series of Ints\n",
    "    return pd.Series(np.array(clean_signals).astype(np.int))\n",
    "\n",
    "\n",
    "def filter_signals(df, signal_column, lookahead_days):\n",
    "    \"\"\"\n",
    "    Filter out signals in a DataFrame.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Stock prices with dates and ticker symbols\n",
    "    signal_column : str\n",
    "        The column with the signals in `df`\n",
    "    lookahead_days : int\n",
    "        The number of days to look ahead\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    signals : Pandas Series\n",
    "        Filtered signals\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "project_tests.test_filter_signals(filter_signals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's view the same chart as before, but with the redundant signals removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['signal_5'] = filter_signals(df, 'signal', 5)\n",
    "df['signal_10'] = filter_signals(df, 'signal', 10)\n",
    "df['signal_20'] = filter_signals(df, 'signal', 20)\n",
    "for signal_days in [5, 10, 20]:\n",
    "    signal_column = 'signal_{}'.format(signal_days)\n",
    "    project_helper.plot_signal(\n",
    "        df[df['ticker'] == apple_ticker],\n",
    "        'Long and Short of {} Stock with {} day signal window'.format(apple_ticker, signal_days),\n",
    "        signal_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookahead Close Prices\n",
    "With the trading signal done, we can start working on evaluating how many days to short or long the stocks. In this problem, implement `get_lookahead_prices` to get the close price days ahead in time. You can get the number of days from the variable `lookahead_days`. We'll use the lookahead prices to calculate future returns in another problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lookahead_prices(df, lookahead_days):\n",
    "    \"\"\"\n",
    "    Get the lookahead prices for `lookahead_days` days.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Stock prices with dates and ticker symbols\n",
    "    lookahead_days : int\n",
    "        The number of days to look ahead\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    lookahead_prices : Pandas Series\n",
    "        The lookahead prices\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_get_lookahead_prices(get_lookahead_prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Using the `get_lookahead_prices` function, let's generate lookahead closing prices for 5, 10, and 20 days.\n",
    "\n",
    "Let's also chart a subsection of a few months of the Apple stock instead of years. This will allow you to view the differences between the 5, 10, and 20 day lookaheads. Otherwise, they will mesh together when looking at a chart that zoomed out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lookahead_5'] = get_lookahead_prices(df, 5)\n",
    "df['lookahead_10'] = get_lookahead_prices(df, 10)\n",
    "df['lookahead_20'] = get_lookahead_prices(df, 20)\n",
    "project_helper.plot_lookahead_prices(\n",
    "    df[df['ticker'] == apple_ticker].iloc[150:250],\n",
    "    ['lookahead_5', 'lookahead_10', 'lookahead_20'],\n",
    "    '5, 10, and 20 day Lookahead Prices for Slice of {} Stock'.format(apple_ticker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookahead Price Returns\n",
    "Implement `get_return_lookahead` to generate the log price return between the closing price and the lookahead price. The lookahead prices are located in the column provided by the `lookahead_column` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_return_lookahead(df, lookahead_column):\n",
    "    \"\"\"\n",
    "    Calculate the price return from the lookahead days to the signal day.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Stock prices with dates and ticker symbols\n",
    "    lookahead_column : str\n",
    "        The column with the lookahead prices in `df`\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    return_lookahead : Pandas Series\n",
    "        The lookahead price returns\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_get_return_lookahead(get_return_lookahead)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Using the same lookahead prices and same subsection of the Apple stock from the previous problem, we'll view the lookahead returns.\n",
    "\n",
    "In order to view price returns on the same chart as the stock, a second y-axis will be added. When viewing this chart, the axis for the price of the stock will be on the left side, like previous charts. The axis for price returns will be located on the right side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['priceReturn_5'] = get_return_lookahead(df, 'lookahead_5')\n",
    "df['priceReturn_10'] = get_return_lookahead(df, 'lookahead_10')\n",
    "df['priceReturn_20'] = get_return_lookahead(df, 'lookahead_20')\n",
    "project_helper.plot_price_returns(\n",
    "    df[df['ticker'] == apple_ticker].iloc[150:250],\n",
    "    ['priceReturn_5', 'priceReturn_10', 'priceReturn_20'],\n",
    "    '5, 10, and 20 day Lookahead Returns for Slice {} Stock'.format(apple_ticker))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the Signal Return\n",
    "Using the price returns from the column provided by `return_column`, generate the signal returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_signal_return(df, return_column, signal_column):\n",
    "    \"\"\"\n",
    "    Compute the signal returns.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Stock prices with dates and ticker symbols\n",
    "    return_column : str\n",
    "        The column with the returns in `df`\n",
    "    signal_column : str\n",
    "        The column with the signals in `df`\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    signal_return : Pandas Series\n",
    "        Signal returns\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_get_signal_return(get_signal_return)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's continue using the previous lookahead prices to view the signal returns. Just like before, the axis for the signal returns is on the right side of the chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_string = '{} day LookaheadSignal Returns for {} Stock'\n",
    "df['signalReturn_5'] = get_signal_return(df, 'priceReturn_5', 'signal_5')\n",
    "df['signalReturn_10'] = get_signal_return(df, 'priceReturn_10', 'signal_10')\n",
    "df['signalReturn_20'] = get_signal_return(df, 'priceReturn_20', 'signal_20')\n",
    "project_helper.plot_signal_returns(\n",
    "    df[df['ticker'] == apple_ticker],\n",
    "    ['signalReturn_5', 'signalReturn_10', 'signalReturn_20'],\n",
    "    ['signal_5', 'signal_10', 'signal_20'],\n",
    "    [title_string.format(5, apple_ticker), title_string.format(10, apple_ticker), title_string.format(20, apple_ticker)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for Significance\n",
    "### Histogram\n",
    "Let's plot a histogram of the signal return values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_helper.plot_series_histograms(\n",
    "    [df['signalReturn_5'], df['signalReturn_10'], df['signalReturn_20']],\n",
    "    'Signal Return',\n",
    "    ('5 Days', '10 Days', '20 Days'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What do the histograms tell you about the signal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*#TODO: Put Answer In this Cell*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P-Value\n",
    "Let's calculate the P-Value from the signal return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pval_5 = project_helper.get_signal_return_pval(df['signalReturn_5'])\n",
    "print('5  Day P-value: {}'.format(pval_5))\n",
    "pval_10 = project_helper.get_signal_return_pval(df['signalReturn_10'])\n",
    "print('10 Day P-value: {}'.format(pval_10))\n",
    "pval_20 = project_helper.get_signal_return_pval(df['signalReturn_20'])\n",
    "print('20 Day P-value: {}'.format(pval_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What do the p-values tell you about the signal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*#TODO: Put Answer In this Cell*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "You might have noticed the outliers in the 10 and 20 day histograms. To better visualize the outliers, let's compare the 5, 10, and 20 day signals returns to normal distributions with the same mean and deviation for each signal return distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_helper.plot_series_to_normal_histograms(\n",
    "    [df['signalReturn_5'], df['signalReturn_10'], df['signalReturn_20']],\n",
    "    'Signal Return',\n",
    "    ('5 Days', '10 Days', '20 Days'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Outliers\n",
    "While you can see the outliers in the histogram, we need to find the stocks that are cause these outlying returns. \n",
    "\n",
    "Implement the function `find_outliers` to use Kolmogorov-Smirnov test (KS test) between a normal distribution and each stock's signal returns in the following order: \n",
    "- Ignore rows without signals in `signal_column`. This will better fit the normal distribution and remove false positives.\n",
    "- Run KS test on a normal distribution that with the same std and mean of all the signal returns in `signal_return_column` against each stock's signal returns in `signal_return_column`. You can use `kstest` or `ks_2samp` to perform the KS test.\n",
    "- Ignore any items that don't pass the null hypothesis with a threshold of `pvalue_threshold`. You can consider them not outliers.\n",
    "- Return all stock tickers with a KS value above `ks_threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from scipy.stats import kstest, ks_2samp, norm\n",
    "\n",
    "def find_outliers(df, signal_column, signal_return_column, ks_threshold, pvalue_threshold=0.05):\n",
    "    \"\"\"\n",
    "    Find stock outliers in `df` using Kolmogorov-Smirnov test against a normal distribution.\n",
    "    \n",
    "    Ignore stock with a p-value from Kolmogorov-Smirnov test greater than `pvalue_threshold`.\n",
    "    Ignore stocks with KS static value lower than `ks_threshold`.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Stock prices with dates and ticker symbols\n",
    "    signal_column : str\n",
    "        The column with the signals in `df`\n",
    "    signal_return_column : str\n",
    "        The column with the signal returns in `df`\n",
    "    ks_threshold : float\n",
    "        The threshold for the KS static\n",
    "    pvalue_threshold : float\n",
    "        The threshold for the p-value\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    outliers : list of str\n",
    "        Symbols that are outliers\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_find_outliers(find_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Using the `find_outliers` function you implemented, let's see what we found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_tickers = []\n",
    "ks_threshold = 0.7\n",
    "\n",
    "outlier_tickers.extend(find_outliers(df, 'signal_5', 'signalReturn_5', ks_threshold))\n",
    "outlier_tickers.extend(find_outliers(df, 'signal_10', 'signalReturn_10', ks_threshold))\n",
    "outlier_tickers.extend(find_outliers(df, 'signal_20', 'signalReturn_20', ks_threshold))\n",
    "outlier_tickers = list(set(outlier_tickers))\n",
    "print('{} Outliers Found:\\n{}'.format(len(outlier_tickers), ', '.join(outlier_tickers)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "You might be asking yourself, \"Why are we removing perfectly good data? The outliers we found just have a huge amount of growth\". That's because we want our returns to reflect future returns. Our signal having high returns for a sector that is out extremely performing the market doesn't reflect how good our signal is. We want to evaluate how a signal will perform in the future, not in the past. These stocks will be removed from our signal analysis and while trading. That doesn't mean those returns will go unnoticed. If this was our job, we would look into ways of better trading those stocks after we finished this analysis.\n",
    "\n",
    "Implement `remove_outliers` to remove the outliers (`outlier_symbols`) from the DataFrame. Return the new DataFrame without the outlier stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df, outlier_symbols):\n",
    "    \"\"\"\n",
    "    Compute the signal return.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : DataFrame\n",
    "        Stock prices with dates and ticker symbols\n",
    "    outlier_symbols : list of str\n",
    "        The outlier stocks to remove from `df`\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    outliers : Dataframe\n",
    "        `df` with the outliers removed\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_remove_outliers(remove_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Significance without Outliers\n",
    "Let's compare the 5, 10, and 20 day signals returns without outliers to normal distributions. Also, let's see how the P-Value has changed with the outliers removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove outliers\n",
    "outliers_removed_df = remove_outliers(df, list(set(outlier_tickers)))\n",
    "\n",
    "project_helper.plot_series_to_normal_histograms(\n",
    "    [outliers_removed_df['signalReturn_5'], outliers_removed_df['signalReturn_10'], outliers_removed_df['signalReturn_20']],\n",
    "    'Signal Return Without Outliers',\n",
    "    ('5 Days', '10 Days', '20 Days'))\n",
    "\n",
    "outliers_removed_pval_5 = project_helper.get_signal_return_pval(outliers_removed_df['signalReturn_5'])\n",
    "outliers_removed_pval_10 = project_helper.get_signal_return_pval(outliers_removed_df['signalReturn_10'])\n",
    "outliers_removed_pval_20 = project_helper.get_signal_return_pval(outliers_removed_df['signalReturn_20'])\n",
    "\n",
    "print('5  Day P-value (with outliers):    {}'.format(pval_5))\n",
    "print('5  Day P-value (without outliers): {}'.format(outliers_removed_pval_5))\n",
    "print('')\n",
    "print('10 Day P-value (with outliers):    {}'.format(pval_10))\n",
    "print('10 Day P-value (without outliers): {}'.format(outliers_removed_pval_10))\n",
    "print('')\n",
    "print('20 Day P-value (with outliers):    {}'.format(pval_20))\n",
    "print('20 Day P-value (without outliers): {}'.format(outliers_removed_pval_20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's more like it! The returns are closer to a normal distribution. You have finished the research phase of a Breakout Strategy. You can now submit your project.\n",
    "## Submission\n",
    "Now that you're done with the project, it's time to submit it. Click the submit button in the bottom right. One of our reviewers will give you feedback on your project with a pass or not passed grade. You can continue to the next section while you wait for feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
